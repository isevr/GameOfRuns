{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "from fastapi import FastAPI, Form\n",
    "from fastapi.responses import HTMLResponse\n",
    "from fastapi.templating import Jinja2Templates\n",
    "from fastapi.requests import Request\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from uuid import uuid4\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "from API.model.preprocessing import data_load\n",
    "from API.model.model_training import model_training\n",
    "import re\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_mining(team, opponent, df, curr_team, season):\n",
    "    combined_df = df.replace({str(team): 'same', str(opponent): 'other'}, regex=True)\n",
    "    \n",
    "    transformed_data = {}\n",
    "    encoders = []\n",
    "    for column in combined_df.columns[:-1]:\n",
    "        le = LabelEncoder()\n",
    "        encoders.append(le)\n",
    "        transformed_data[column] = le.fit_transform(combined_df[column])\n",
    "    \n",
    "    transformed_df = pd.DataFrame(transformed_data)\n",
    "    df = pd.concat([transformed_df, combined_df[combined_df.columns[-1]]], axis=1)\n",
    "    \n",
    "    undersample_len = len(df[df['class'] == 1])\n",
    "    undersample_df = df[df['class'] == 0].sample(n=undersample_len, random_state=43)\n",
    "    df = pd.concat([df[df['class'] == 1], undersample_df])\n",
    "    \n",
    "    events_idx = {}\n",
    "    total_sequences = len(df[df['class'] == 1])\n",
    "    freqs = []\n",
    "    \n",
    "    for j, event in zip(range(12, 112, 11), range(10, 0, -1)):\n",
    "        event_len_df = df[df['class'] == 1].iloc[:, -j:-1] \n",
    "        total_sequences_same_length = len(event_len_df)\n",
    "        \n",
    "        event_dict = {}\n",
    "        row_counts = defaultdict(int)\n",
    "        \n",
    "        for i in range(len(event_len_df)):\n",
    "            row_tuple = tuple(event_len_df.iloc[i])\n",
    "            row_counts[row_tuple] += 1\n",
    "            \n",
    "        \n",
    "        sorted_row_counts = sorted(row_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        total_seqs = 0\n",
    "        for i in range(10):\n",
    "            total_seqs += sorted_row_counts[i][1]\n",
    "\n",
    "        \n",
    "        if sorted_row_counts:\n",
    "            mc_row, max_count = sorted_row_counts[0]\n",
    "            sc_row, second_max_count = sorted_row_counts[1] if len(sorted_row_counts) > 1 else (None, 0)\n",
    "        else:\n",
    "            mc_row, max_count, sc_row, second_max_count = None, 0, None, 0\n",
    "        \n",
    "        max_count_ratio = max_count / total_seqs\n",
    "        second_max_count_ratio = second_max_count / total_seqs\n",
    "        \n",
    "        mc_indices = event_len_df.apply(lambda row: tuple(row) == mc_row, axis=1)\n",
    "        mc_indices = mc_indices[mc_indices].index.tolist()\n",
    "        \n",
    "        sc_indices = event_len_df.apply(lambda row: tuple(row) == sc_row, axis=1)\n",
    "        sc_indices = sc_indices[sc_indices].index.tolist()\n",
    "        \n",
    "        events_idx[event] = mc_indices\n",
    "        \n",
    "        event_dict['Event'] = abs(event - 11)\n",
    "        event_dict['Frequency'] = max_count\n",
    "        event_dict['Ratio'] = np.round(max_count_ratio, 4)\n",
    "        event_dict['Sec Frequency'] = second_max_count\n",
    "        event_dict['Sec Ratio'] = np.round(second_max_count_ratio, 4)\n",
    "        \n",
    "        try:\n",
    "            event_dict['Sequence'] = str(combined_df.iloc[mc_indices[0], -j:-1].to_frame().dropna().T.to_dict(orient=\"records\"))\n",
    "        except IndexError:\n",
    "            print(mc_indices, j, curr_team, season)\n",
    "\n",
    "        try:\n",
    "            event_dict['Sec Sequence'] = str(combined_df.iloc[sc_indices[0], -j:-1].to_frame().dropna().T.to_dict(orient=\"records\"))\n",
    "        except IndexError:\n",
    "            print(sc_indices, j, curr_team, season)\n",
    "        \n",
    "        freqs.append(event_dict)\n",
    "    \n",
    "    return pd.DataFrame(freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_team(team, season, venue):\n",
    "    og_df = pd.read_csv('data/'+season)\n",
    "\n",
    "    def team_selection(pref_team, df):\n",
    "        if pref_team in df.HomeTeam.unique():\n",
    "            pref_df = df[df.HomeTeam == pref_team]\n",
    "            return pref_df\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "\n",
    "    new_df = team_selection(team, og_df)\n",
    "\n",
    "    if new_df is None:\n",
    "        print(f\"No data found for team {team} in {season}\")\n",
    "        return [] \n",
    "\n",
    "    factors = ['ShotDist','TimeoutTeam','Substitution', 'Shooter',\n",
    "               'Rebounder', 'Blocker','Fouler',\n",
    "               'ReboundType','ViolationPlayer',\n",
    "               'FreeThrowShooter','TurnoverPlayer']\n",
    "\n",
    "    fact_cols = [col + str((i // 11) % 10 + 1) for i, col in enumerate(factors * 10)]\n",
    "    fact_cols.append('class')\n",
    "\n",
    "    new_df['ShotDist'] = new_df.ShotDist.apply(lambda x: 'close' if x <= 10 else '3pt' if x >= 22 else 'mid' if pd.notna(x) else x)\n",
    "    \n",
    "    new_df['TimeoutTeam'] = new_df.apply(\n",
    "        lambda row: 'timeout_home' if pd.notna(row['TimeoutTeam']) and row['TimeoutTeam'] == row['HomeTeam'] \n",
    "        else 'timeout_away' if pd.notna(row['TimeoutTeam']) \n",
    "        else row['TimeoutTeam'], \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    new_df['Shooter'] = new_df.apply(lambda row: 'shooter_home' if pd.notna(row['Shooter']) and pd.notna(row['HomePlay'])\n",
    "                                         else 'shooter_away' if pd.notna(row['Shooter']) and pd.notna(row['AwayPlay'])\n",
    "                                         else np.nan,\n",
    "                                         axis=1)\n",
    "\n",
    "    new_df['Rebounder'] = new_df.apply(lambda row: 'rebounder_home' if pd.notna(row['Rebounder']) and pd.notna(row['HomePlay'])\n",
    "                                         else 'rebounder_away' if pd.notna(row['Rebounder']) and pd.notna(row['AwayPlay'])\n",
    "                                         else np.nan,\n",
    "                                         axis=1)\n",
    "\n",
    "    new_df['Blocker'] = new_df.apply(lambda row: 'blocker_home' if pd.notna(row['Blocker']) and pd.notna(row['HomePlay'])\n",
    "                                         else 'blocker_away' if pd.notna(row['Blocker']) and pd.notna(row['AwayPlay'])\n",
    "                                         else np.nan,\n",
    "                                         axis=1)\n",
    "\n",
    "    new_df['Fouler'] = new_df.apply(lambda row: 'fouler_home' if pd.notna(row['Fouler']) and pd.notna(row['HomePlay'])\n",
    "                                         else 'fouler_away' if pd.notna(row['Fouler']) and pd.notna(row['AwayPlay'])\n",
    "                                         else np.nan,\n",
    "                                         axis=1)\n",
    "\n",
    "    new_df['ViolationPlayer'] = new_df.apply(lambda row: 'violator_home' if pd.notna(row['ViolationPlayer']) and pd.notna(row['HomePlay'])\n",
    "                                         else 'violator_away' if pd.notna(row['ViolationPlayer']) and pd.notna(row['AwayPlay'])\n",
    "                                         else np.nan,\n",
    "                                         axis=1)\n",
    "\n",
    "    new_df['FreeThrowShooter'] = new_df.apply(lambda row: 'ft_home' if pd.notna(row['FreeThrowShooter']) and pd.notna(row['HomePlay'])\n",
    "                                         else 'ft_away' if pd.notna(row['FreeThrowShooter']) and pd.notna(row['AwayPlay'])\n",
    "                                         else np.nan,\n",
    "                                         axis=1)\n",
    "\n",
    "    new_df['TurnoverPlayer'] = new_df.apply(lambda row: 'to_player_home' if pd.notna(row['TurnoverPlayer']) and pd.notna(row['HomePlay'])\n",
    "                                         else 'to_player_away' if pd.notna(row['TurnoverPlayer']) and pd.notna(row['AwayPlay'])\n",
    "                                         else np.nan,\n",
    "                                         axis=1)\n",
    "\n",
    "    new_df['Substitution'] = new_df.apply(lambda row: 'sub_home' if pd.notna(row['EnterGame']) and pd.notna(row['HomePlay'])\n",
    "                                                  else 'sub_away' if pd.notna(row['EnterGame']) and pd.notna(row['AwayPlay'])\n",
    "                                                  else np.nan,\n",
    "                                                  axis=1)\n",
    "\n",
    "    def home_runner(data):\n",
    "        home_runs = []\n",
    "        current_run = []\n",
    "        for idx in data.index:\n",
    "            home_made_shot = pd.notna(data.at[idx, 'HomePlay']) and 'makes' in data.at[idx, 'HomePlay']\n",
    "            away_made_shot = pd.notna(data.at[idx, 'AwayPlay']) and 'makes' in data.at[idx, 'AwayPlay']\n",
    "\n",
    "            if home_made_shot:\n",
    "                current_run.append(idx)\n",
    "            elif away_made_shot:\n",
    "                if len(current_run) >= 4:\n",
    "                    home_runs.append(current_run.copy())\n",
    "                current_run.clear()\n",
    "                \n",
    "        if len(current_run) >= 4:\n",
    "            home_runs.append(current_run.copy())\n",
    "            \n",
    "        return home_runs\n",
    "\n",
    "    def away_runner(data):\n",
    "        away_runs = []\n",
    "        current_run = []\n",
    "        for idx in data.index:\n",
    "            away_made_shot = pd.notna(data.at[idx, 'AwayPlay']) and 'makes' in data.at[idx, 'AwayPlay']\n",
    "            home_made_shot = pd.notna(data.at[idx, 'HomePlay']) and 'makes' in data.at[idx, 'HomePlay']\n",
    "\n",
    "            if away_made_shot:\n",
    "                current_run.append(idx)\n",
    "            elif home_made_shot:\n",
    "                if len(current_run) >= 4:\n",
    "                    away_runs.append(current_run.copy())\n",
    "                current_run.clear()\n",
    "\n",
    "        if len(current_run) >= 4:\n",
    "            away_runs.append(current_run.copy())\n",
    "            \n",
    "        return away_runs\n",
    "\n",
    "    home_runs = home_runner(new_df)\n",
    "    away_runs = away_runner(new_df)\n",
    "\n",
    "    all_runs = []\n",
    "    all_runs.extend(home_runs)\n",
    "    all_runs.extend(away_runs)\n",
    "\n",
    "    new_df = new_df[factors]\n",
    "\n",
    "    def runs_iter(data, runs):\n",
    "        runs_df = pd.DataFrame()\n",
    "        for run in runs:\n",
    "            if run[0]-10 in data.index and run[0]-1 in data.index:\n",
    "                a = data.loc[run[0]-10:run[0]-1, factors].values.ravel()\n",
    "                a = np.append(a,1)\n",
    "                runs_df = pd.concat([runs_df,pd.DataFrame([a.copy()])])\n",
    "        return runs_df\n",
    "\n",
    "    venue_runs = home_runs if venue == 'home' else away_runs\n",
    "    \n",
    "    runs_df = runs_iter(new_df, venue_runs)\n",
    "    \n",
    "    if not runs_df.empty:\n",
    "        runs_df.columns = fact_cols\n",
    "        runs_df['class'] = runs_df['class'].fillna(1)\n",
    "    else:\n",
    "        runs_df = pd.DataFrame(columns=fact_cols)\n",
    "\n",
    "\n",
    "    def no_runs_preprocessing(data, runs):\n",
    "        r = [i[0] for i in runs]  \n",
    "        r_x = []\n",
    "        for num in r:\n",
    "            r_x.extend(range(num - 10, num + 1))\n",
    "\n",
    "        no_runs_df = data[~data.index.isin(r_x)].reset_index(drop=True)\n",
    "\n",
    "        segment_size = 10\n",
    "        segments = len(no_runs_df) // segment_size\n",
    "\n",
    "        if segments > 0:\n",
    "            no_runs_split = np.array_split(no_runs_df, segments)\n",
    "        else:\n",
    "            no_runs_split = []\n",
    "\n",
    "        no_runs_split = [x for x in no_runs_split if len(x) == 10]\n",
    "\n",
    "        return no_runs_split\n",
    "\n",
    "    def no_runs_optimized(data, factors, fact_cols):\n",
    "        if not data: \n",
    "            return pd.DataFrame(columns=fact_cols) \n",
    "            \n",
    "        no_runs_df = pd.DataFrame([np.append(segment.loc[:, factors].values.ravel(), int(0)) for segment in data])\n",
    "        no_runs_df.columns = fact_cols\n",
    "        return no_runs_df\n",
    "\n",
    "    processed_no_runs = no_runs_preprocessing(new_df, venue_runs)\n",
    "    no_runs_df = no_runs_optimized(processed_no_runs, factors, fact_cols)\n",
    "\n",
    "    combined_df = pd.concat([runs_df,no_runs_df],ignore_index=True)\n",
    "    \n",
    "    if combined_df.empty:\n",
    "        print(f\"No run or no-run sequences found for {team} {season} {venue}\")\n",
    "        return [] \n",
    "\n",
    "    os.makedirs('team_runs', exist_ok=True)\n",
    "    combined_df.to_csv('team_runs/'+str(team)+'_'+str(venue)+'_runs.csv', index=False)\n",
    "    combined_df = pd.read_csv('team_runs/'+str(team)+'_'+str(venue)+'_runs.csv')\n",
    "\n",
    "\n",
    "    if venue == 'home':\n",
    "        df_data = sequence_mining('home', 'away',combined_df, team, season)\n",
    "    elif venue == 'away':\n",
    "         df_data = sequence_mining('away', 'home' ,combined_df, team, season)\n",
    "\n",
    "    df_data = df_data.to_dict(orient=\"records\")\n",
    "\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = ['DET', 'CLE', 'NOP', 'WAS', 'PHI', 'CHI', 'UTA', 'CHO', 'IND',\n",
    "       'DEN', 'NYK', 'SAS', 'DAL', 'LAC', 'MIN', 'MEM', 'ATL', 'MIA',\n",
    "       'OKC', 'TOR', 'BRK', 'GSW', 'LAL', 'POR', 'PHO', 'SAC', 'HOU',\n",
    "       'MIL', 'ORL', 'BOS']\n",
    "\n",
    "seasons = ['NBA_PBP_2015-16.csv', \n",
    "        'NBA_PBP_2016-17.csv',\n",
    "        'NBA_PBP_2017-18.csv',\n",
    "        'NBA_PBP_2018-19.csv',\n",
    "        'NBA_PBP_2019-20.csv',\n",
    "        ]\n",
    "\n",
    "venues = ['home', 'away']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data processed and concatenated.\n"
     ]
    }
   ],
   "source": [
    "all_dfs = []\n",
    "\n",
    "for team in teams:\n",
    "    for season in seasons:\n",
    "        for venue in venues:\n",
    "            try:\n",
    "                team_mining_list = analyze_team(team, season, venue)\n",
    "                \n",
    "                if team_mining_list:\n",
    "                    for record in team_mining_list:\n",
    "                        record['team'] = team\n",
    "                        record['season'] = re.sub(r'[^0-9-]+','',season)\n",
    "                        record['venue'] = venue\n",
    "                    \n",
    "                    team_df = pd.DataFrame(team_mining_list)\n",
    "                    all_dfs.append(team_df)\n",
    "                \n",
    "            except IndexError:\n",
    "                print(f\"IndexError processing {team} {season} {venue}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {team} {season} {venue}: {e}\")\n",
    "\n",
    "if all_dfs:\n",
    "    all_data = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(\"All data processed and concatenated.\")\n",
    "else:\n",
    "    print(\"No data was processed.\")\n",
    "    all_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_db():\n",
    "    conn = sqlite3.connect('frequencies_new.db')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "                    CREATE TABLE IF NOT EXISTS freqs(\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                event TEXT,\n",
    "                frequency INTEGER,\n",
    "                ratio REAL,\n",
    "                sec_frequency INTEGER,\n",
    "                sec_ratio REAL,\n",
    "                team TEXT,\n",
    "                season TEXT,\n",
    "                venue TEXT,\n",
    "                sequence TEXT,\n",
    "                sec_sequence TEXT\n",
    "                )\n",
    "                '''\n",
    "                )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "initialize_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_dict = all_data.to_dict(orient='records')\n",
    "\n",
    "records_to_insert = [\n",
    "    (\n",
    "        record.get('Event'),\n",
    "        record.get('Frequency'),\n",
    "        record.get('Ratio'),\n",
    "        record.get('Sec Frequency'),\n",
    "        record.get('Sec Ratio'),\n",
    "        record.get('team'),\n",
    "        record.get('season'),\n",
    "        record.get('venue'),\n",
    "        record.get('Sequence'),\n",
    "        record.get('Sec Sequence')\n",
    "    )\n",
    "    for record in all_data_dict\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('frequencies_new.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.executemany('''\n",
    "                    INSERT INTO freqs (\n",
    "                   event, frequency, ratio, sec_frequency, sec_ratio, team, season, venue, sequence, sec_sequence)\n",
    "                   VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "                   ''', records_to_insert)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"[{'Fouler10': 'fouler_same'}]\",)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect('frequencies_new.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('''\n",
    "                SELECT sequence FROM freqs\n",
    "               ''')\n",
    "\n",
    "seqs = cursor.fetchall()\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "seqs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import re\n",
    "\n",
    "def browse_patterns(team, season, db):\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "                SELECT \n",
    "        event,\n",
    "        SUM(frequency) AS total_frequency,\n",
    "        AVG(ratio) AS total_ratio,\n",
    "        sequence,\n",
    "        SUM(sec_frequency) AS total_sec_frequency,\n",
    "        AVG(sec_ratio) as total_sec_ratio,\n",
    "        sec_sequence,\n",
    "        season,\n",
    "        venue\n",
    "        \n",
    "    FROM \n",
    "        freqs\n",
    "    WHERE team = ? and event != '10' and season = ?\n",
    "    GROUP BY \n",
    "        event\n",
    "    ORDER BY \n",
    "        event ASC\n",
    "    LIMIT 5\n",
    "\n",
    "                ''', (team, re.sub(r'NBA_PBP_|.csv','',season)))\n",
    "    \n",
    "\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "\n",
    "    df_rows = pd.DataFrame(rows)\n",
    "    df_rows.columns = ['event','total_frequency','total_ratio', 'sequence', \n",
    "                    'total_sec_frequency', 'total_sec_ratio', 'sec_sequence', 'season', 'venue']\n",
    "\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return df_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from openpyxl import load_workbook, Workbook\n",
    "\n",
    "def browse_patterns(teams, seasons, db, output_file):\n",
    "    \"\"\"\n",
    "    Creates an Excel file with separate sheets for each team.\n",
    "    If a team's sheet exists, it appends new season data to it.\n",
    "    \n",
    "    Args:\n",
    "        teams (list): List of team names.\n",
    "        seasons (list): List of seasons to query.\n",
    "        db (str): Path to the SQLite database.\n",
    "        output_file (str): Output Excel file name.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    if not os.path.exists(output_file) or os.stat(output_file).st_size == 0:\n",
    "        print(f'Creating new file: {output_file}')\n",
    "        book = Workbook()\n",
    "        book.save(output_file)\n",
    "\n",
    "    book = load_workbook(output_file)\n",
    "        \n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "        writer._book = book  \n",
    "\n",
    "        for team in teams:\n",
    "            for season in seasons:\n",
    "                clean_season = re.sub(r'NBA_PBP_|.csv', '', season)\n",
    "                \n",
    "                cursor.execute('''\n",
    "                    SELECT \n",
    "                        event,\n",
    "                        SUM(frequency) AS total_frequency,\n",
    "                        AVG(ratio) AS total_ratio,\n",
    "                        sequence,\n",
    "                        SUM(sec_frequency) AS total_sec_frequency,\n",
    "                        AVG(sec_ratio) as total_sec_ratio,\n",
    "                        sec_sequence,\n",
    "                        season,\n",
    "                        venue\n",
    "                    FROM \n",
    "                        freqs\n",
    "                    WHERE team = ? AND event != '10' AND season = ?\n",
    "                    GROUP BY \n",
    "                        event, venue\n",
    "                    ORDER BY \n",
    "                        event ASC\n",
    "                    LIMIT 10\n",
    "                ''', (team, clean_season))\n",
    "                \n",
    "                rows = cursor.fetchall()\n",
    "                df_rows = pd.DataFrame(rows, columns=['event','total_frequency','total_ratio', 'sequence', \n",
    "                    'total_sec_frequency', 'total_sec_ratio', 'sec_sequence', 'season', 'venue'])\n",
    "                \n",
    "                if df_rows.empty:\n",
    "                    print(f\"No data found for {team} {clean_season}\")\n",
    "                    continue\n",
    "\n",
    "                if team in book.sheetnames:\n",
    "                    startrow = book[team].max_row\n",
    "                    df_rows.to_excel(writer, sheet_name=team, index=False, startrow=startrow, header=False)\n",
    "                else:\n",
    "                    df_rows.to_excel(writer, sheet_name=team, index=False)\n",
    "\n",
    "                print(f\"Added season {clean_season} data for team {team} to {output_file}\")\n",
    "\n",
    "    try:\n",
    "        book = load_workbook(output_file)\n",
    "        if \"Sheet\" in book.sheetnames and len(book.sheetnames) > 1:\n",
    "            book.remove(book[\"Sheet\"])\n",
    "            book.save(output_file)\n",
    "            print(\"Removed default 'Sheet' from the final file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not remove default 'Sheet': {e}\")\n",
    "        \n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added season 2015-16 data for team DET to queries.xlsx\n",
      "Added season 2016-17 data for team DET to queries.xlsx\n",
      "Added season 2017-18 data for team DET to queries.xlsx\n",
      "Added season 2018-19 data for team DET to queries.xlsx\n",
      "Added season 2019-20 data for team DET to queries.xlsx\n",
      "Added season 2015-16 data for team CLE to queries.xlsx\n",
      "Added season 2016-17 data for team CLE to queries.xlsx\n",
      "Added season 2017-18 data for team CLE to queries.xlsx\n",
      "Added season 2018-19 data for team CLE to queries.xlsx\n",
      "Added season 2019-20 data for team CLE to queries.xlsx\n",
      "Added season 2015-16 data for team NOP to queries.xlsx\n",
      "Added season 2016-17 data for team NOP to queries.xlsx\n",
      "Added season 2017-18 data for team NOP to queries.xlsx\n",
      "Added season 2018-19 data for team NOP to queries.xlsx\n",
      "Added season 2019-20 data for team NOP to queries.xlsx\n",
      "Added season 2015-16 data for team WAS to queries.xlsx\n",
      "Added season 2016-17 data for team WAS to queries.xlsx\n",
      "Added season 2017-18 data for team WAS to queries.xlsx\n",
      "Added season 2018-19 data for team WAS to queries.xlsx\n",
      "Added season 2019-20 data for team WAS to queries.xlsx\n",
      "Added season 2015-16 data for team PHI to queries.xlsx\n",
      "Added season 2016-17 data for team PHI to queries.xlsx\n",
      "Added season 2017-18 data for team PHI to queries.xlsx\n",
      "Added season 2018-19 data for team PHI to queries.xlsx\n",
      "Added season 2019-20 data for team PHI to queries.xlsx\n",
      "Added season 2015-16 data for team CHI to queries.xlsx\n",
      "Added season 2016-17 data for team CHI to queries.xlsx\n",
      "Added season 2017-18 data for team CHI to queries.xlsx\n",
      "Added season 2018-19 data for team CHI to queries.xlsx\n",
      "Added season 2019-20 data for team CHI to queries.xlsx\n",
      "Added season 2015-16 data for team UTA to queries.xlsx\n",
      "Added season 2016-17 data for team UTA to queries.xlsx\n",
      "Added season 2017-18 data for team UTA to queries.xlsx\n",
      "Added season 2018-19 data for team UTA to queries.xlsx\n",
      "Added season 2019-20 data for team UTA to queries.xlsx\n",
      "Added season 2015-16 data for team CHO to queries.xlsx\n",
      "Added season 2016-17 data for team CHO to queries.xlsx\n",
      "Added season 2017-18 data for team CHO to queries.xlsx\n",
      "Added season 2018-19 data for team CHO to queries.xlsx\n",
      "Added season 2019-20 data for team CHO to queries.xlsx\n",
      "Added season 2015-16 data for team IND to queries.xlsx\n",
      "Added season 2016-17 data for team IND to queries.xlsx\n",
      "Added season 2017-18 data for team IND to queries.xlsx\n",
      "Added season 2018-19 data for team IND to queries.xlsx\n",
      "Added season 2019-20 data for team IND to queries.xlsx\n",
      "Added season 2015-16 data for team DEN to queries.xlsx\n",
      "Added season 2016-17 data for team DEN to queries.xlsx\n",
      "Added season 2017-18 data for team DEN to queries.xlsx\n",
      "Added season 2018-19 data for team DEN to queries.xlsx\n",
      "Added season 2019-20 data for team DEN to queries.xlsx\n",
      "Added season 2015-16 data for team NYK to queries.xlsx\n",
      "Added season 2016-17 data for team NYK to queries.xlsx\n",
      "Added season 2017-18 data for team NYK to queries.xlsx\n",
      "Added season 2018-19 data for team NYK to queries.xlsx\n",
      "Added season 2019-20 data for team NYK to queries.xlsx\n",
      "Added season 2015-16 data for team SAS to queries.xlsx\n",
      "Added season 2016-17 data for team SAS to queries.xlsx\n",
      "Added season 2017-18 data for team SAS to queries.xlsx\n",
      "Added season 2018-19 data for team SAS to queries.xlsx\n",
      "Added season 2019-20 data for team SAS to queries.xlsx\n",
      "Added season 2015-16 data for team DAL to queries.xlsx\n",
      "Added season 2016-17 data for team DAL to queries.xlsx\n",
      "Added season 2017-18 data for team DAL to queries.xlsx\n",
      "Added season 2018-19 data for team DAL to queries.xlsx\n",
      "Added season 2019-20 data for team DAL to queries.xlsx\n",
      "Added season 2015-16 data for team LAC to queries.xlsx\n",
      "Added season 2016-17 data for team LAC to queries.xlsx\n",
      "Added season 2017-18 data for team LAC to queries.xlsx\n",
      "Added season 2018-19 data for team LAC to queries.xlsx\n",
      "Added season 2019-20 data for team LAC to queries.xlsx\n",
      "Added season 2015-16 data for team MIN to queries.xlsx\n",
      "Added season 2016-17 data for team MIN to queries.xlsx\n",
      "Added season 2017-18 data for team MIN to queries.xlsx\n",
      "Added season 2018-19 data for team MIN to queries.xlsx\n",
      "Added season 2019-20 data for team MIN to queries.xlsx\n",
      "Added season 2015-16 data for team MEM to queries.xlsx\n",
      "Added season 2016-17 data for team MEM to queries.xlsx\n",
      "Added season 2017-18 data for team MEM to queries.xlsx\n",
      "Added season 2018-19 data for team MEM to queries.xlsx\n",
      "Added season 2019-20 data for team MEM to queries.xlsx\n",
      "Added season 2015-16 data for team ATL to queries.xlsx\n",
      "Added season 2016-17 data for team ATL to queries.xlsx\n",
      "Added season 2017-18 data for team ATL to queries.xlsx\n",
      "Added season 2018-19 data for team ATL to queries.xlsx\n",
      "Added season 2019-20 data for team ATL to queries.xlsx\n",
      "Added season 2015-16 data for team MIA to queries.xlsx\n",
      "Added season 2016-17 data for team MIA to queries.xlsx\n",
      "Added season 2017-18 data for team MIA to queries.xlsx\n",
      "Added season 2018-19 data for team MIA to queries.xlsx\n",
      "Added season 2019-20 data for team MIA to queries.xlsx\n",
      "Added season 2015-16 data for team OKC to queries.xlsx\n",
      "Added season 2016-17 data for team OKC to queries.xlsx\n",
      "Added season 2017-18 data for team OKC to queries.xlsx\n",
      "Added season 2018-19 data for team OKC to queries.xlsx\n",
      "Added season 2019-20 data for team OKC to queries.xlsx\n",
      "Added season 2015-16 data for team TOR to queries.xlsx\n",
      "Added season 2016-17 data for team TOR to queries.xlsx\n",
      "Added season 2017-18 data for team TOR to queries.xlsx\n",
      "Added season 2018-19 data for team TOR to queries.xlsx\n",
      "Added season 2019-20 data for team TOR to queries.xlsx\n",
      "Added season 2015-16 data for team BRK to queries.xlsx\n",
      "Added season 2016-17 data for team BRK to queries.xlsx\n",
      "Added season 2017-18 data for team BRK to queries.xlsx\n",
      "Added season 2018-19 data for team BRK to queries.xlsx\n",
      "Added season 2019-20 data for team BRK to queries.xlsx\n",
      "Added season 2015-16 data for team GSW to queries.xlsx\n",
      "Added season 2016-17 data for team GSW to queries.xlsx\n",
      "Added season 2017-18 data for team GSW to queries.xlsx\n",
      "Added season 2018-19 data for team GSW to queries.xlsx\n",
      "Added season 2019-20 data for team GSW to queries.xlsx\n",
      "Added season 2015-16 data for team LAL to queries.xlsx\n",
      "Added season 2016-17 data for team LAL to queries.xlsx\n",
      "Added season 2017-18 data for team LAL to queries.xlsx\n",
      "Added season 2018-19 data for team LAL to queries.xlsx\n",
      "Added season 2019-20 data for team LAL to queries.xlsx\n",
      "Added season 2015-16 data for team POR to queries.xlsx\n",
      "Added season 2016-17 data for team POR to queries.xlsx\n",
      "Added season 2017-18 data for team POR to queries.xlsx\n",
      "Added season 2018-19 data for team POR to queries.xlsx\n",
      "Added season 2019-20 data for team POR to queries.xlsx\n",
      "Added season 2015-16 data for team PHO to queries.xlsx\n",
      "Added season 2016-17 data for team PHO to queries.xlsx\n",
      "Added season 2017-18 data for team PHO to queries.xlsx\n",
      "Added season 2018-19 data for team PHO to queries.xlsx\n",
      "Added season 2019-20 data for team PHO to queries.xlsx\n",
      "Added season 2015-16 data for team SAC to queries.xlsx\n",
      "Added season 2016-17 data for team SAC to queries.xlsx\n",
      "Added season 2017-18 data for team SAC to queries.xlsx\n",
      "Added season 2018-19 data for team SAC to queries.xlsx\n",
      "Added season 2019-20 data for team SAC to queries.xlsx\n",
      "Added season 2015-16 data for team HOU to queries.xlsx\n",
      "Added season 2016-17 data for team HOU to queries.xlsx\n",
      "Added season 2017-18 data for team HOU to queries.xlsx\n",
      "Added season 2018-19 data for team HOU to queries.xlsx\n",
      "Added season 2019-20 data for team HOU to queries.xlsx\n",
      "Added season 2015-16 data for team MIL to queries.xlsx\n",
      "Added season 2016-17 data for team MIL to queries.xlsx\n",
      "Added season 2017-18 data for team MIL to queries.xlsx\n",
      "Added season 2018-19 data for team MIL to queries.xlsx\n",
      "Added season 2019-20 data for team MIL to queries.xlsx\n",
      "Added season 2015-16 data for team ORL to queries.xlsx\n",
      "Added season 2016-17 data for team ORL to queries.xlsx\n",
      "Added season 2017-18 data for team ORL to queries.xlsx\n",
      "Added season 2018-19 data for team ORL to queries.xlsx\n",
      "Added season 2019-20 data for team ORL to queries.xlsx\n",
      "Added season 2015-16 data for team BOS to queries.xlsx\n",
      "Added season 2016-17 data for team BOS to queries.xlsx\n",
      "Added season 2017-18 data for team BOS to queries.xlsx\n",
      "Added season 2018-19 data for team BOS to queries.xlsx\n",
      "Added season 2019-20 data for team BOS to queries.xlsx\n",
      "Removed default 'Sheet' from the final file.\n"
     ]
    }
   ],
   "source": [
    "browse_patterns(teams, seasons, 'frequencies_new.db','queries.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
