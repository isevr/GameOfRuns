{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "from fastapi import FastAPI, Form\n",
    "from fastapi.responses import HTMLResponse\n",
    "from fastapi.templating import Jinja2Templates\n",
    "from fastapi.requests import Request\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from uuid import uuid4\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "from preprocessing import data_load\n",
    "from model_training import model_training\n",
    "import re\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sequence_mining(team, opponent, df, curr_team, season):\n",
    "    # Replace team names with generic labels\n",
    "    combined_df = df.replace({str(team): 'same', str(opponent): 'other'}, regex=True)\n",
    "    \n",
    "    transformed_data = {}\n",
    "    encoders = []\n",
    "    for column in combined_df.columns[:-1]:\n",
    "        le = LabelEncoder()\n",
    "        encoders.append(le)\n",
    "        transformed_data[column] = le.fit_transform(combined_df[column])\n",
    "    \n",
    "    transformed_df = pd.DataFrame(transformed_data)\n",
    "    df = pd.concat([transformed_df, combined_df[combined_df.columns[-1]]], axis=1)\n",
    "    \n",
    "    # Undersample to balance the dataset\n",
    "    undersample_len = len(df[df['class'] == 1])\n",
    "    undersample_df = df[df['class'] == 0].sample(n=undersample_len, random_state=43)\n",
    "    df = pd.concat([df[df['class'] == 1], undersample_df])\n",
    "    \n",
    "    events_idx = {}\n",
    "    total_sequences = len(df[df['class'] == 1])\n",
    "    freqs = []\n",
    "    \n",
    "    for j, event in zip(range(12, 112, 11), range(10, 0, -1)):\n",
    "        event_len_df = df[df['class'] == 1].iloc[:, -j:-1] \n",
    "        total_sequences_same_length = len(event_len_df)\n",
    "        \n",
    "        event_dict = {}\n",
    "        row_counts = defaultdict(int)\n",
    "        \n",
    "        for i in range(len(event_len_df)):\n",
    "            row_tuple = tuple(event_len_df.iloc[i])\n",
    "            row_counts[row_tuple] += 1\n",
    "            \n",
    "        \n",
    "        sorted_row_counts = sorted(row_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        total_seqs = 0\n",
    "        for i in range(10):\n",
    "            total_seqs += sorted_row_counts[i][1]\n",
    "\n",
    "        \n",
    "        if sorted_row_counts:\n",
    "            mc_row, max_count = sorted_row_counts[0]\n",
    "            sc_row, second_max_count = sorted_row_counts[1] if len(sorted_row_counts) > 1 else (None, 0)\n",
    "        else:\n",
    "            mc_row, max_count, sc_row, second_max_count = None, 0, None, 0\n",
    "        \n",
    "        max_count_ratio = max_count / total_seqs\n",
    "        second_max_count_ratio = second_max_count / total_seqs\n",
    "        \n",
    "        mc_indices = event_len_df.apply(lambda row: tuple(row) == mc_row, axis=1)\n",
    "        mc_indices = mc_indices[mc_indices].index.tolist()\n",
    "        \n",
    "        sc_indices = event_len_df.apply(lambda row: tuple(row) == sc_row, axis=1)\n",
    "        sc_indices = sc_indices[sc_indices].index.tolist()\n",
    "        \n",
    "        events_idx[event] = mc_indices\n",
    "        \n",
    "        event_dict['Event'] = abs(event - 11)\n",
    "        event_dict['Frequency'] = max_count\n",
    "        event_dict['Ratio'] = np.round(max_count_ratio, 4)\n",
    "        event_dict['Sec Frequency'] = second_max_count\n",
    "        event_dict['Sec Ratio'] = np.round(second_max_count_ratio, 4)\n",
    "        \n",
    "        try:\n",
    "            event_dict['Sequence'] = str(combined_df.iloc[mc_indices[0], -j:-1].to_frame().dropna().T.to_dict(orient=\"records\"))\n",
    "        except IndexError:\n",
    "            print(mc_indices, j, curr_team, season)\n",
    "\n",
    "        try:\n",
    "            event_dict['Sec Sequence'] = str(combined_df.iloc[sc_indices[0], -j:-1].to_frame().dropna().T.to_dict(orient=\"records\"))\n",
    "        except IndexError:\n",
    "            print(sc_indices, j, curr_team, season)\n",
    "        \n",
    "        freqs.append(event_dict)\n",
    "    \n",
    "    return pd.DataFrame(freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_team(team, season, venue):\n",
    "    og_df = pd.read_csv('data/'+season)\n",
    "\n",
    "    def team_selection(pref_team, df):\n",
    "        if pref_team in df.HomeTeam.unique():\n",
    "            pref_df = df[df.HomeTeam == pref_team]\n",
    "            return pref_df\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "\n",
    "    new_df = team_selection(team, og_df)\n",
    "\n",
    "\n",
    "    factors = ['ShotDist','TimeoutTeam','Substitution', 'Shooter',\n",
    "               'Rebounder', 'Blocker','Fouler',\n",
    "               'ReboundType','ViolationPlayer',\n",
    "               'FreeThrowShooter','TurnoverPlayer']\n",
    "\n",
    "    fact_cols = [col + str((i // 11) % 10 + 1) for i, col in enumerate(factors * 10)]\n",
    "    fact_cols.append('class')\n",
    "\n",
    "    new_df['ShotDist'] = new_df.ShotDist.apply(lambda x: 'close' if x <= 10 else '3pt' if x >= 22 else 'mid' if pd.notna(x) else x)\n",
    "    \n",
    "    new_df['TimeoutTeam'] = new_df.apply(\n",
    "        lambda row: 'timeout_home' if pd.notna(row['TimeoutTeam']) and row['TimeoutTeam'] == row['HomeTeam'] \n",
    "        else 'timeout_away' if pd.notna(row['TimeoutTeam']) \n",
    "        else row['TimeoutTeam'], \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    new_df['Shooter'] = new_df.apply(lambda row: 'shooter_home' if pd.notna(row['Shooter']) and pd.notna(row['HomePlay'])\n",
    "                                         else 'shooter_away' if pd.notna(row['Shooter']) and pd.notna(row['AwayPlay'])\n",
    "                                         else np.nan,\n",
    "                                         axis=1)\n",
    "\n",
    "    new_df['Rebounder'] = new_df.apply(lambda row: 'rebounder_home' if pd.notna(row['Rebounder']) and pd.notna(row['HomePlay'])\n",
    "                                         else 'rebounder_away' if pd.notna(row['Rebounder']) and pd.notna(row['AwayPlay'])\n",
    "                                         else np.nan,\n",
    "                                         axis=1)\n",
    "\n",
    "    new_df['Blocker'] = new_df.apply(lambda row: 'blocker_home' if pd.notna(row['Blocker']) and pd.notna(row['HomePlay'])\n",
    "                                         else 'blocker_away' if pd.notna(row['Blocker']) and pd.notna(row['AwayPlay'])\n",
    "                                         else np.nan,\n",
    "                                         axis=1)\n",
    "\n",
    "    new_df['Fouler'] = new_df.apply(lambda row: 'fouler_home' if pd.notna(row['Fouler']) and pd.notna(row['HomePlay'])\n",
    "                                         else 'fouler_away' if pd.notna(row['Fouler']) and pd.notna(row['AwayPlay'])\n",
    "                                         else np.nan,\n",
    "                                         axis=1)\n",
    "\n",
    "    new_df['ViolationPlayer'] = new_df.apply(lambda row: 'violator_home' if pd.notna(row['ViolationPlayer']) and pd.notna(row['HomePlay'])\n",
    "                                         else 'violator_away' if pd.notna(row['ViolationPlayer']) and pd.notna(row['AwayPlay'])\n",
    "                                         else np.nan,\n",
    "                                         axis=1)\n",
    "\n",
    "    new_df['FreeThrowShooter'] = new_df.apply(lambda row: 'ft_home' if pd.notna(row['FreeThrowShooter']) and pd.notna(row['HomePlay'])\n",
    "                                         else 'ft_away' if pd.notna(row['FreeThrowShooter']) and pd.notna(row['AwayPlay'])\n",
    "                                         else np.nan,\n",
    "                                         axis=1)\n",
    "\n",
    "    new_df['TurnoverPlayer'] = new_df.apply(lambda row: 'to_player_home' if pd.notna(row['TurnoverPlayer']) and pd.notna(row['HomePlay'])\n",
    "                                         else 'to_player_away' if pd.notna(row['TurnoverPlayer']) and pd.notna(row['AwayPlay'])\n",
    "                                         else np.nan,\n",
    "                                         axis=1)\n",
    "\n",
    "    new_df['Substitution'] = new_df.apply(lambda row: 'sub_home' if pd.notna(row['EnterGame']) and pd.notna(row['HomePlay'])\n",
    "                                                  else 'sub_away' if pd.notna(row['EnterGame']) and pd.notna(row['AwayPlay'])\n",
    "                                                  else np.nan,\n",
    "                                                  axis=1)\n",
    "\n",
    "    def home_runner(data):\n",
    "        global home_runs\n",
    "        run = []\n",
    "        home_runs = []\n",
    "        for idx in data.index:\n",
    "            if data.at[idx,'HomePlay'] is not np.nan:\n",
    "                    if 'makes' in data.at[idx,'HomePlay']:\n",
    "                        run.append(idx)\n",
    "            elif data.at[idx,'AwayPlay'] is not np.nan:\n",
    "                    if 'makes' in data.at[idx,'AwayPlay']:\n",
    "                        run.clear()\n",
    "            if len(run) == 4:\n",
    "                home_runs.append(run.copy())\n",
    "                run.clear()\n",
    "        return home_runs\n",
    "                \n",
    "    home_runner(new_df)\n",
    "\n",
    "    def away_runner(data):\n",
    "        global away_runs\n",
    "        run = []\n",
    "        away_runs = []\n",
    "        for idx in data.index:\n",
    "            if data.at[idx,'AwayPlay'] is not np.nan:\n",
    "                    if 'makes' in data.at[idx,'AwayPlay']:\n",
    "                        run.append(idx)\n",
    "            elif data.at[idx,'HomePlay'] is not np.nan:\n",
    "                    if 'makes' in data.at[idx,'HomePlay']:\n",
    "                        run.clear()\n",
    "            if len(run) == 4:\n",
    "                away_runs.append(run.copy())\n",
    "                run.clear()\n",
    "        return away_runs\n",
    "\n",
    "    away_runner(new_df)\n",
    "\n",
    "    all_runs = []\n",
    "    all_runs.extend(home_runs)\n",
    "    all_runs.extend(away_runs)\n",
    "\n",
    "    new_df = new_df[factors]\n",
    "\n",
    "    def runs_iter(data, runs):\n",
    "        global runs_df\n",
    "        runs_df = pd.DataFrame()\n",
    "        for run in runs:\n",
    "            a = data.loc[run[0]-10:run[0]-1, factors].values.ravel()\n",
    "            a = np.append(a,1)\n",
    "            runs_df = pd.concat([runs_df,pd.DataFrame([a.copy()])])\n",
    "        return runs_df\n",
    "\n",
    "    venue_runs = home_runs if venue == 'home' else away_runs\n",
    "    runs_iter(new_df, venue_runs)\n",
    "    runs_df.columns = fact_cols\n",
    "    runs_df['class'] = runs_df['class'].fillna(1)\n",
    "\n",
    "\n",
    "    def no_runs_preprocessing(data, runs):\n",
    "        global no_runs_split\n",
    "\n",
    "        # find the first index of a run\n",
    "        r = [i[0] for i in runs]  \n",
    "\n",
    "        # create a list of runs\n",
    "        r_x = []\n",
    "        for num in r:\n",
    "            r_x.extend(range(num - 10, num + 1))\n",
    "\n",
    "        # mask the df without runs\n",
    "        no_runs_df = data[~data.index.isin(r_x)].reset_index(drop=True)\n",
    "\n",
    "        # segment the df and keep those that are length of 10\n",
    "        segment_size = 10\n",
    "        segments = len(no_runs_df) // segment_size\n",
    "\n",
    "        no_runs_split = np.array_split(no_runs_df, segments)\n",
    "\n",
    "        no_runs_split = [x for x in no_runs_split if len(x) != 11]\n",
    "\n",
    "        return no_runs_split\n",
    "\n",
    "    def no_runs_optimized(data, factors, fact_cols):\n",
    "        global no_runs_df\n",
    "        no_runs_df = pd.DataFrame([np.append(segment.loc[:, factors].values.ravel(), int(0)) for segment in data])\n",
    "        no_runs_df.columns = fact_cols\n",
    "        return no_runs_df\n",
    "\n",
    "    no_runs_optimized(no_runs_preprocessing(new_df, venue_runs), factors, fact_cols)\n",
    "\n",
    "    combined_df = pd.concat([runs_df,no_runs_df],ignore_index=True)\n",
    "    combined_df.to_csv('team_runs/'+str(team)+'_'+str(venue)+'_runs.csv', index=False)\n",
    "    combined_df = pd.read_csv('team_runs/'+str(team)+'_'+str(venue)+'_runs.csv')\n",
    "\n",
    "\n",
    "    if venue == 'home':\n",
    "        df_data = sequence_mining('home', 'away',combined_df, team, season)\n",
    "    elif venue == 'away':\n",
    "         df_data = sequence_mining('away', 'home' ,combined_df, team, season)\n",
    "\n",
    "    df_data = df_data.to_dict(orient=\"records\")\n",
    "\n",
    "    return df_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = ['DET', 'CLE', 'NOP', 'WAS', 'PHI', 'CHI', 'UTA', 'CHO', 'IND',\n",
    "       'DEN', 'NYK', 'SAS', 'DAL', 'LAC', 'MIN', 'MEM', 'ATL', 'MIA',\n",
    "       'OKC', 'TOR', 'BRK', 'GSW', 'LAL', 'POR', 'PHO', 'SAC', 'HOU',\n",
    "       'MIL', 'ORL', 'BOS']\n",
    "\n",
    "seasons = ['NBA_PBP_2015-16.csv', \n",
    "        'NBA_PBP_2016-17.csv',\n",
    "        'NBA_PBP_2017-18.csv',\n",
    "        'NBA_PBP_2018-19.csv',\n",
    "        'NBA_PBP_2019-20.csv',\n",
    "        ]\n",
    "\n",
    "venues = ['home', 'away']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for team in teams:\n",
    "    for season in seasons:\n",
    "        for venue in venues:\n",
    "            try:\n",
    "                team_mining = analyze_team(team, season, venue)\n",
    "                team_mining['team'] = team\n",
    "                team_mining['season'] = re.sub(r'[^0-9-]+','',season)\n",
    "                team_mining['venue'] = venue\n",
    "                dfs.append(team_mining)\n",
    "            except IndexError:\n",
    "                print(team, season)\n",
    "\n",
    "all_data = pd.concat(dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_db():\n",
    "    conn = sqlite3.connect('frequencies.db')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "                    CREATE TABLE IF NOT EXISTS freqs(\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                event TEXT,\n",
    "                frequency INTEGER,\n",
    "                ratio REAL,\n",
    "                sec_frequency INTEGER,\n",
    "                sec_ratio REAL,\n",
    "                team TEXT,\n",
    "                season TEXT,\n",
    "                venue TEXT,\n",
    "                sequence TEXT,\n",
    "                sec_sequence TEXT\n",
    "                )\n",
    "                '''\n",
    "                )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "initialize_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_dict = all_data.to_dict(orient='records')\n",
    "\n",
    "records_to_insert = [\n",
    "    (\n",
    "        record.get('Event'),\n",
    "        record.get('Frequency'),\n",
    "        record.get('Ratio'),\n",
    "        record.get('Sec Frequency'),\n",
    "        record.get('Sec Ratio'),\n",
    "        record.get('team'),\n",
    "        record.get('season'),\n",
    "        record.get('venue'),\n",
    "        record.get('Sequence'),\n",
    "        record.get('Sec Sequence')\n",
    "    )\n",
    "    for record in all_data_dict\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('frequencies_s.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.executemany('''\n",
    "                    INSERT INTO freqs (\n",
    "                   event, frequency, ratio, sec_frequency, sec_ratio, team, season, venue, sequence, sec_sequence)\n",
    "                   VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "                   ''', records_to_insert)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"[{'Fouler10': 'fouler_same'}]\",)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect('frequencies.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('''\n",
    "                SELECT sequence FROM freqs\n",
    "               ''')\n",
    "\n",
    "seqs = cursor.fetchall()\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "seqs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import re\n",
    "\n",
    "def browse_patterns(team, season, db):\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "                SELECT \n",
    "        event,\n",
    "        SUM(frequency) AS total_frequency,\n",
    "        AVG(ratio) AS total_ratio,\n",
    "        sequence,\n",
    "        SUM(sec_frequency) AS total_sec_frequency,\n",
    "        AVG(sec_ratio) as total_sec_ratio,\n",
    "        sec_sequence,\n",
    "        season,\n",
    "        venue\n",
    "        \n",
    "    FROM \n",
    "        freqs\n",
    "    WHERE team = ? and event != '10' and season = ?\n",
    "    GROUP BY \n",
    "        event\n",
    "    ORDER BY \n",
    "        event ASC\n",
    "    LIMIT 5\n",
    "\n",
    "                ''', (team, re.sub(r'NBA_PBP_|.csv','',season)))\n",
    "    \n",
    "\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "\n",
    "    df_rows = pd.DataFrame(rows)\n",
    "    df_rows.columns = ['event','total_frequency','total_ratio', 'sequence', \n",
    "                    'total_sec_frequency', 'total_sec_ratio', 'sec_sequence', 'season', 'venue']\n",
    "\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return df_rows\n",
    "\n",
    "# best_freq = 0\n",
    "# second_best_freq = 0\n",
    "\n",
    "# for team in teams[:1]:\n",
    "#     for season in seasons[:1]:\n",
    "#         df = browse_patterns(team, season)\n",
    "        \n",
    "#         if df.iloc[1].total_frequency > best_freq:\n",
    "#             best_freq = df.iloc[1].total_frequency\n",
    "#             print(team, season)\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>total_frequency</th>\n",
       "      <th>total_ratio</th>\n",
       "      <th>total_sec_frequency</th>\n",
       "      <th>total_sec_ratio</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>0.33835</td>\n",
       "      <td>31</td>\n",
       "      <td>0.15890</td>\n",
       "      <td>2016-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.17740</td>\n",
       "      <td>14</td>\n",
       "      <td>0.15515</td>\n",
       "      <td>2016-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.15095</td>\n",
       "      <td>7</td>\n",
       "      <td>0.13175</td>\n",
       "      <td>2016-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.13380</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10880</td>\n",
       "      <td>2016-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.17425</td>\n",
       "      <td>3</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>2016-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  event  total_frequency  total_ratio  total_sec_frequency  total_sec_ratio  \\\n",
       "0     1               66      0.33835                   31          0.15890   \n",
       "1     2               16      0.17740                   14          0.15515   \n",
       "2     3                8      0.15095                    7          0.13175   \n",
       "3     4                5      0.13380                    4          0.10880   \n",
       "4     5                4      0.17425                    3          0.12880   \n",
       "\n",
       "    season  \n",
       "0  2016-17  \n",
       "1  2016-17  \n",
       "2  2016-17  \n",
       "3  2016-17  \n",
       "4  2016-17  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browse_patterns('DET', seasons[1],'frequencies.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from openpyxl import load_workbook, Workbook\n",
    "\n",
    "def browse_patterns(teams, seasons, db, output_file):\n",
    "    \"\"\"\n",
    "    Creates an Excel file with separate sheets for each team.\n",
    "    If a team's sheet exists, it appends new season data to it.\n",
    "    \n",
    "    Args:\n",
    "        teams (list): List of team names.\n",
    "        seasons (list): List of seasons to query.\n",
    "        db (str): Path to the SQLite database.\n",
    "        output_file (str): Output Excel file name.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Check if the file exists, if not, create a valid blank Excel file\n",
    "    if not os.path.exists(output_file) or os.stat(output_file).st_size == 0:\n",
    "        print('creating book')\n",
    "        wb = Workbook()\n",
    "        ws = wb.active\n",
    "        ws.title = \"TempSheet\"\n",
    "        wb.save(output_file)\n",
    "\n",
    "    # Load the existing workbook\n",
    "    book = load_workbook(output_file)\n",
    "\n",
    "    # Remove the temporary sheet if it's the only one\n",
    "    if \"TempSheet\" in book.sheetnames and len(book.sheetnames) == 1:\n",
    "        book.remove(book[\"TempSheet\"])\n",
    "        book.save(output_file)\n",
    "\n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "        writer._book = book  \n",
    "\n",
    "        for team in teams:\n",
    "            for season in seasons:\n",
    "                cursor.execute('''\n",
    "                    SELECT \n",
    "        event,\n",
    "        SUM(frequency) AS total_frequency,\n",
    "        AVG(ratio) AS total_ratio,\n",
    "        sequence,\n",
    "        SUM(sec_frequency) AS total_sec_frequency,\n",
    "        AVG(sec_ratio) as total_sec_ratio,\n",
    "        sec_sequence,\n",
    "        season,\n",
    "        venue\n",
    "                    FROM \n",
    "                        freqs\n",
    "                    WHERE team = ? AND event != '10' AND season = ?\n",
    "                    GROUP BY \n",
    "                        event, venue\n",
    "                    ORDER BY \n",
    "                        event ASC\n",
    "                    LIMIT 10\n",
    "                ''', (team, re.sub(r'NBA_PBP_|.csv', '', season)))\n",
    "                \n",
    "                rows = cursor.fetchall()\n",
    "                df_rows = pd.DataFrame(rows, columns=['event','total_frequency','total_ratio', 'sequence', \n",
    "                    'total_sec_frequency', 'total_sec_ratio', 'sec_sequence', 'season', 'venue'])\n",
    "                \n",
    "                if team in book.sheetnames:\n",
    "                    startrow = book[team].max_row\n",
    "                    df_rows.to_excel(writer, sheet_name=team, index=False, startrow=startrow, header=False)\n",
    "                else:\n",
    "                    df_rows.to_excel(writer, sheet_name=team, index=False)\n",
    "\n",
    "                print(f\"Added season {season} data for team {team} to {output_file}\")\n",
    "\n",
    "\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browse_patterns(teams, seasons, 'frequencies.db','queries_ven.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
